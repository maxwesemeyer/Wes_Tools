import rasterio.mask
from affine import Affine
import matplotlib.pyplot as plt
import pandas as pd
import itertools
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
from skimage import segmentation
import torch.nn.init
from sklearn.preprocessing import MinMaxScaler
import imageio
from sklearn import decomposition
from .__utils import *
#import cv2
########################################################################################################################


def set_global_Cnn_variables(bands=11, convs=2,):
    """
    CNN needs some global variables
    :param bands: number of bands to be used for CNN
    :param convs: number of convolutions
    :return:
    """
    # CNN model
    global n_band
    global nConv
    global padd
    global stride_
    n_band = bands
    nConv = convs
    padd = np.int((n_band - 1) / 2)
    stride_ = 1


class MyNet(nn.Module):
    def __init__(self, input_dim):
        super(MyNet, self).__init__()
        self.conv1 = nn.Conv2d(input_dim, n_band, kernel_size=n_band, stride=stride_, padding=padd)
        self.bn1 = nn.BatchNorm2d(n_band)
        self.conv2 = nn.ModuleList()
        self.bn2 = nn.ModuleList()
        for i in range(nConv - 1):  # n_conv
            self.conv2.append(nn.Conv2d(n_band, n_band, kernel_size=n_band, stride=stride_, padding=padd))
            self.bn2.append(nn.BatchNorm2d(n_band))
        self.conv3 = nn.Conv2d(n_band, n_band, kernel_size=1, stride=stride_, padding=0)
        self.bn3 = nn.BatchNorm2d(n_band)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.bn1(x)
        """
        #### experimenting
        x_ = x.detach().numpy()
        x_ = x_.squeeze()
        x_ = np.moveaxis(x_, 0, 2)
        plt.imshow(x_)
        plt.show()
        #### experimenting
        """
        for i in range(nConv - 1):
            x = self.conv2[i](x)
            x = F.relu(x)
            x = self.bn2[i](x)
        x = self.conv3(x)
        x = self.bn3(x)
        return x


def OpenRasterToMemory(path):
    drvMemR = gdal.GetDriverByName('MEM')
    ds = gdal.Open(path)
    dsMem = drvMemR.CreateCopy('', ds)
    return dsMem


def minmax_transfor(X):
    shape = X.shape
    i = shape[0]
    j = shape[1]
    bands = shape[2]
    result = 255 * (img1[i, j, bands] - np.nanmin(img1[:, :, bands])) / (
            np.nanmax(img1[:, :, bands]) - np.nanmin(img1[:, :, bands]))
    return result

class Segmentation():
    prepare_data = []


def segment_cnn(raster_l, vector_geom, data_path, indexo=np.random.randint(0, 100000), custom_subsetter=range(5,65),n_band=11, nConv = 1, lr_var=0.15):
    """
        :param string_to_raster: path to raster file
        :param vector_mask: list of fiona geometries
        :param n_band: How many PCs will be used
        :param into_pca: How many bands schould be used for the PCA; By default all
        :param custom_subsetter: In case not to use all the input bands
        :param data_path_output: Where to save the results?
        :param MMU: Minumum Mapping Unit in km²; below that input will be set as one segment
        :return: saves segmented image to disk using the Bayseg
         # the default should be string_to_raster = tss
        # raster_tsi = string_to_raster.replace('TSS', 'TSI')
        range(0, 35 * 14) for coreg stack
        """
    field_counter = "{}{}{}{}{}{}{}".format(str(n_band), '_', str(nConv), '_', str(lr_var), '_', str(indexo))
    shp = [vector_geom.geometry]
    subsetter_tss = custom_subsetter
    subsetter_tsi = custom_subsetter
    with rasterio.open(raster_l) as src:
        out_image, out_transform = rasterio.mask.mask(src, shp, crop=True)

        create_mask = True
        if create_mask:
            mask = create_mask_from_ndim(out_image)

    with rasterio.open(raster_l) as src:
        out_image_agg, out_mask_agg = rasterio.mask.mask(src, shp, crop=True)
        out_image_agg = out_image_agg.copy() / 10000
        out_image_agg = out_image_agg[subsetter_tsi, :, :]
        shape_out_tsi = out_image_agg.shape

        gt_gdal = Affine.to_gdal(out_transform)
        #################################

        out_meta = src.meta

        out_image = out_image.copy() / 10000
        out_image = out_image[subsetter_tsi, :, :]
        shape_out = out_image.shape
        max_valid_pixel = (sum(np.reshape(mask[:, :], (shape_out[1] * shape_out[2])) > 0))
        print('Parcel Area:', max_valid_pixel * 100 / 1000000, ' km²')
        if max_valid_pixel * 100 / 1000000 < 0.05:
            print('pass')
            pass
        else:
            w = np.where(out_image < 0)

            out_sub = mask[:, :]
            mask_local = np.where(out_sub <= 0)
            out_image[w] = 0
            out_image_nan = out_image.copy().astype(dtype=np.float)
            out_image_nan[w] = np.nan
            std_glob = np.nanstd(out_image_nan, axis=(1, 2))
            print('global:', sum(std_glob))

            three_band_img = out_image_nan
            img1 = np.moveaxis(three_band_img, 0, 2)




            re = np.reshape(img1, (img1.shape[0] * img1.shape[1], img1.shape[2]))
            # re_scale = RobustScaler(quantile_range=(0.8, 1)).fit_transform(re)
            scaled = (MinMaxScaler(feature_range=(0, 255)).fit_transform(re))
            scaled_shaped = np.reshape(scaled, (img1.shape))
            # scaled_shaped = np.square(img1+10)
            wh_nan = np.where(np.isnan(scaled_shaped))
            scaled_shaped[wh_nan] = 0

            ###########
            # selects bands which have only valid pixels
            arg_10 = select_bands_sd(out_image_nan, max_valid_pixels_=max_valid_pixel)
            print(arg_10)

            # labels = segmentation.felzenszwalb(scaled_shaped[:,:,arg_10[:3]], scale=10)
            # labels = segmentation.slic(scaled_shaped[:,:,arg], n_segments=6, compactness=6)
            # labels = segmentation.slic(scaled_shaped[:, :, arg], n_segments=90, compactness=15)

            im = scaled_shaped[:, :, arg_10]
            im[im == 0] = np.nan

            scaled_arg_2d = np.reshape(im, (im.shape[0] * im.shape[1], len(arg_10)))
            # plt.hist(scaled_arg_2d[:,0], bins = 50)
            # plt.show()

            im[np.isnan(im)] = 0
            adjust = 0

            n_comp = 4 - adjust

            scaled_arg_2d[np.isnan(scaled_arg_2d)] = 0
            print(scaled_arg_2d)
            #################
            # PCA
            n_comps = n_band
            pca = decomposition.PCA(n_components=n_comps)
            im_pca = pca.fit_transform(scaled_arg_2d)
            print(pca.explained_variance_ratio_)
            image_pca = np.reshape(im_pca, (im.shape[0], im.shape[1], n_comps))
            im_pca[im_pca == 0] = np.nan
            print('IMAGE PCA', image_pca.shape)

            # labels = KMeans(n_clusters=5).fit_predict(scaled_arg_2d)
            # labels = segmentation.felzenszwalb(scaled_shaped[:, :, arg_10[:3]], scale=2)  #
            labels = segmentation.slic(image_pca, n_segments=100, compactness=10)

            im = image_pca
            file_str = "{}{}{}".format(data_path + "/output/out_labels", str(field_counter), "_")

            labels_img = np.reshape(labels, (image_pca.shape[0], image_pca.shape[1]))
            # labels__img = np.reshape(labels_, (scaled_shaped.shape[0], scaled_shaped.shape[1]))
            labels_img += 1
            labels_img[mask_local] = 0
            labels = labels_img.reshape(im.shape[0] * im.shape[1])
            print(im.shape, labels.shape)
            plt.imshow(labels_img)
            plt.show()

            # WriteArrayToDisk(labels_img, file_str, gt_gdal, polygonite=True)
            ################################ cnn stuff
            data = torch.from_numpy(np.array([im.transpose((2, 0, 1)).astype('float32') / 255.]))

            visualize = True
            data = Variable(data)
            u_labels = np.unique(labels)

            l_inds = []
            for i in range(len(u_labels)):
                l_inds.append(np.where(labels == u_labels[i])[0])

            # train
            model = MyNet(data.size(1))

            #if os.path.exists(data_path + 'cnn_model'):
            #model = torch.load(data_path + 'cnn_model')
            model.train()
            loss_fn = torch.nn.CrossEntropyLoss()
            optimizer = optim.SGD(model.parameters(), lr=lr_var, momentum=0.8)
            label_colours = np.random.randint(255, size=(100, n_band))
            # to create a gif
            images = []
            for batch_idx in range(500):
                # forwarding
                optimizer.zero_grad()
                output = model(data)[0]
                output = output.permute(1, 2, 0).contiguous().view(-1, n_band)
                ignore, target = torch.max(output, 1)
                im_target = target.data.cpu().numpy()
                nLabels = len(np.unique(im_target))

                if visualize:
                    im_target_rgb = np.array([label_colours[c % 100] for c in im_target])

                    im_target_rgb = im_target_rgb.reshape(im.shape).astype(np.uint8)
                    shp_1 = (np.sqrt(im_target_rgb.shape[0])).astype(np.int)

                    # im_target_rgb = im_target_rgb.reshape((shp_1, shp_1, 10)).astype(np.uint8)

                    images.append((im_target_rgb[:, :, 0]))

                    # cv2.imshow("output", im_target_rgb[:, :, [0, 1, 2]])
                    # cv2.waitKey(n_band)

                # superpixel refinement
                # TODO: use Torch Variable instead of numpy for faster calculation
                for i in range(len(l_inds)):
                    labels_per_sp = im_target[l_inds[i]]
                    u_labels_per_sp = np.unique(labels_per_sp)
                    hist = np.zeros(len(u_labels_per_sp))
                    for j in range(len(hist)):
                        hist[j] = len(np.where(labels_per_sp == u_labels_per_sp[j])[0])
                    im_target[l_inds[i]] = u_labels_per_sp[np.argmax(hist)]
                target = torch.from_numpy(im_target)

                target = Variable(target)
                loss = loss_fn(output, target)
                loss.backward()
                optimizer.step()

                # print (batch_idx, '/', args.maxIter, ':', nLabels, loss.data[0])
                print(batch_idx, '/', 500, ':', nLabels, loss.item())

                if nLabels < 2:
                    print("nLabels", nLabels, "reached minLabels", 2, ".")
                    break
            #torch.save(model, data_path + 'cnn_model')
            # save output image
            if not visualize:
                output = model(data)[0]
                output = output.permute(1, 2, 0).contiguous().view(-1, n_band)
                ignore, target = torch.max(output, 1)
                im_target = target.data.cpu().numpy()
                im_target_rgb = np.array([label_colours[c % 100] for c in im_target])
                im_target_rgb = im_target_rgb.reshape(im.shape).astype(np.uint8)
            imageio.mimsave(data_path + 'cnn.gif', images)
            print(im_target_rgb.shape)

            flat_array = im_target_rgb[:, :, 0].squeeze()
            flat_array += 1
            flat_array[mask_local] = 0
            print(type(flat_array))

            plt.figure(figsize=(15, 8))
            plt.imshow(flat_array)
            # plt.show()

            file_str = "{}{}{}".format(data_path + "/output/out", str(field_counter), "_")
            WriteArrayToDisk(flat_array, file_str, gt_gdal, polygonite=True, fieldo=field_counter)



"""
# global variables
########################################################################################################################
# raster_string = '/PCA_Berlin_Predict.tif'
#vector_string = '/Invekos_clip_3035.shp'
vector_string = 'Vector/Invekos_Grassland_3035.shp'
data_path = 'H:/MA/'
file_path_raster = []

# find all files in the given directory containing either MODIS or bsq
for root, dirs, files in os.walk(data_path + 'output_folder'):
    for file in files:
        if re.match(".*[t][i][f]{1,2}$", file):
            file_path_raster.append(str(root + '/' + file))
        else:
            continue


print(file_path_raster)
# raster_string = file_path_raster[0]

raster_string ='Z:/BB_vrt_stack/BRB_2.vrt'
raster_for_aggregation = 'Z:/BB_vrt_stack/BRB_2.vrt'

#raster_string = file_path_raster[0]
# tsi 2018 = 146, 218 (-1 already)
# tss 2018 = 54, 122
#subsetter = range(54, 122)
subsetter_tsi = range(146, 218)
subsetter = range(0, 980)

raster = gdal.Open(raster_string)
meta = (raster.GetMetadata())
print(meta)

# raster_arr = raster.ReadAsArray()

field = ogr.Open(data_path + vector_string)
field_lyr = field.GetLayer()

jobs = 3

# desoising the entire image?
n_cluster = 4
add_to_cluster = 1


# when smaller than median = more likely that only one land use in parcel
########################################################################################################################
vector_string = 'O:/Student_Data/Wesemeyer/Projekt_/Shapes/Dissolved_3035.gpkg'
with fiona.open(vector_string) as shapefile:
    shapes = [feature["geometry"] for feature in shapefile]
# a mask for the entire image should be generated
# create array where every field gets a number and append to the pca array; kind of a proximity layer;
# could also add more features e.g. field std
raster_string = 'Z:/lower_saxony_sentinel2_TSA_coreg/X0061_Y0046/stack.tif'


"""